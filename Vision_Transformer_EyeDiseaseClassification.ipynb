{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPC2aBbXK/axsQk6K83wvQA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Neelll1705/Eye-Disease-Classification---ML/blob/main/Vision_Transformer_EyeDiseaseClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7R1MWbN8IndQ"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision transformers\n",
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
        "import timm\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "p4Zse1wXI6av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Upload kaggle.json manually\n",
        "from google.colab import files\n",
        "files.upload()  # Upload kaggle.json when prompted\n",
        "\n",
        "# Step 2: Create kaggle directory and move the json file\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Step 3: Download the dataset\n",
        "!kaggle datasets download -d gunavenkatdoddi/eye-diseases-classification\n",
        "\n",
        "# Step 4: Unzip the downloaded file\n",
        "!unzip eye-diseases-classification.zip\n"
      ],
      "metadata": {
        "id": "ne91EPETI9bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EyeDiseaseDataset(Dataset):\n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Load image paths and labels\n",
        "data_dir = \"/content/dataset\"  # Update this path if necessary\n",
        "classes = os.listdir(data_dir)\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "for class_idx, class_name in enumerate(classes):\n",
        "    class_dir = os.path.join(data_dir, class_name)\n",
        "    for image_name in os.listdir(class_dir):\n",
        "        image_paths.append(os.path.join(class_dir, image_name))\n",
        "        labels.append(class_idx)\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(image_paths, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = EyeDiseaseDataset(train_paths, train_labels, transform=transform)\n",
        "test_dataset = EyeDiseaseDataset(test_paths, test_labels, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "N2CwSeg3JBRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pre-trained ViT model\n",
        "model = timm.create_model('vit_base_patch16_224', pretrained=True, num_classes=len(classes))\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "2q23mAB3JDGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
      ],
      "metadata": {
        "id": "zOP5VHSrJHI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in tqdm(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_accuracy = 100 * correct / total\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "sejfrMM2JIRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(test_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy on test set: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "id": "gesSluepJKjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"eye_disease_vit_model.pth\")"
      ],
      "metadata": {
        "id": "XOkCoAvQJMWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Lists to store loss and accuracy values\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "# Split the training dataset into training and validation sets\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "# Create data loader for the validation set\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in tqdm(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_accuracy = 100 * correct / total\n",
        "\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(epoch_accuracy)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader: # Use the val_loader here\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_losses.append(val_loss / len(val_loader))\n",
        "    val_accuracies.append(100 * correct / total)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_accuracy:.2f}%, \"\n",
        "          f\"Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_accuracies[-1]:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(1, num_epochs + 1), train_losses, label=\"Training Loss\", marker='o')\n",
        "plt.plot(range(1, num_epochs + 1), val_losses, label=\"Validation Loss\", marker='s')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, num_epochs + 1), train_accuracies, label=\"Training Accuracy\", marker='o', color=\"blue\")\n",
        "plt.plot(range(1, num_epochs + 1), val_accuracies, label=\"Validation Accuracy\", marker='s', color=\"orange\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.title(\"Training & Validation Accuracy\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DLBcY2BtUNrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'classes' is a list of class names in the order:\n",
        "# ['glaucoma', 'normal', 'cataract', 'diabetic retinopathy']\n",
        "# If the order is different, adjust the indices accordingly.\n",
        "\n",
        "# Initialize lists to store per-class statistics\n",
        "class_correct = [0] * len(classes)\n",
        "class_total = [0] * len(classes)\n",
        "\n",
        "# Evaluate the model to gather per-class predictions\n",
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "with torch.no_grad():  # Disable gradient calculations\n",
        "    for images, labels in tqdm(test_loader):  # Assuming you're using your test loader\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Update per-class statistics\n",
        "        for i in range(len(labels)):  # Iterate over each element in the batch\n",
        "            label = labels[i].item()  # Get the true label (as a Python integer)\n",
        "            class_total[label] += 1\n",
        "            class_correct[label] += (predicted[i].item() == label)\n",
        "\n",
        "# Print accuracy for specific classes\n",
        "target_classes = ['glaucoma', 'normal', 'cataract', 'diabetic retinopathy']\n",
        "\n",
        "print(\"\\nClass-wise Validation Accuracy:\")\n",
        "for target_class in target_classes:\n",
        "    try:\n",
        "        index = classes.index(target_class)\n",
        "        accuracy = (100 * class_correct[index] / class_total[index]) if class_total[index] > 0 else 0\n",
        "        print(f\"Class {target_class}: {accuracy:.2f}%\")\n",
        "    except ValueError:\n",
        "        print(f\"Class {target_class} not found in the dataset.\")"
      ],
      "metadata": {
        "id": "ue_QlnPrZoZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Initialize lists to store true and predicted labels\n",
        "all_labels = []\n",
        "all_predictions = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(test_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "# Classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(all_labels, all_predictions, target_names=classes))\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NEvD2xWnUR5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a code for showing classification with .h5 file\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "\n",
        "# Load the saved model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = timm.create_model('vit_base_patch16_224', pretrained=False, num_classes=4) # Assuming 4 classes\n",
        "model.load_state_dict(torch.load('eye_disease_vit_model.pth', map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Example usage:\n",
        "# Assuming 'image' is a preprocessed image tensor of shape (1, 3, 224, 224)\n",
        "# and 'classes' is a list of class names.\n",
        "\n",
        "# Example image loading and preprocessing (replace with your actual image loading)\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "example_image = Image.open(\"/content/dataset/glaucoma/1020_left.jpg\").convert(\"RGB\")  # Replace with your image path\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "image = transform(example_image).unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(image)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    predicted_class_index = predicted.item()\n",
        "\n",
        "classes = ['glaucoma', 'normal', 'cataract', 'diabetic retinopathy'] # Replace with your actual class names\n",
        "predicted_class = classes[predicted_class_index]\n",
        "print(f\"Predicted class: {predicted_class}\")\n"
      ],
      "metadata": {
        "id": "9xCvqqItUUiY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}